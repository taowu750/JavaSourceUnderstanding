# 1. 局部性原理

一个优秀的程序、优美的代码，往往具有良好的**局部性**。那么什么是程序的局部性原理呢？
1. **程序局部性原理**：是指程序在执行时呈现出局部性规律，即在一段时间内，整个程序的执行仅限于程序中的某一部分。
相应地，执行所访问的存储空间也局限于某个内存区域，具体来说，局部性通常有两种形式：时间局部性和空间局部性。
2. **时间局部性**：被引用过一次的存储器位置在未来会被多次引用（通常在循环中）。
3. **空间局部性**：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。

# 2. 例子

## 2.1 访问一维数组
```java
int sum(int[] arr) {
    int sum = 0;

    for (int i = 0; i < arr.length; i++)
        sum += arr[i];

    return sum;
}
```
我们知道，数组的特点是在内存中是向下图一样连续存放的。

![一维数组][1d-arr]

根据代码以及局部性定义可知：
1. 对于循环中的`sum`变量：有良好的时间局部性。因为在`for`循环结束之前，每次执行循环体都有对`sum`的访问。而`sum`没有空间局部性。
因为`sum`是标量（也就是说通过`sum`这个地址只能得到一个值）
2. 对于循环体中的`v`变量：有良好的空间局部性。因为数组`v`是按顺序存放在内存中，每次访问`v[i]`总是在`v[i-1]`的下一个位置。
而`v`没有时间局部性，因为在循环体中，每个元素`v[i]`只会被访问一次。

## 2.2 局部性对程序效率的影响
```java
final int LEN = 10000;
int[][] arr = new int[LEN][LEN];

long start, finish;

start = System.currentTimeMillis();
// 先访问行
for (int i = 0; i < LEN; i++) {
    for (int j = 0; j < LEN; j++) {
        arr[i][j] = j;
    }
}
finish = System.currentTimeMillis();
System.out.println("行优先访问消耗时间：" + (finish - start) + "ms");

start = System.currentTimeMillis();
// 先访问列
for (int j = 0; j < LEN; j++) {
    for (int i = 0; i < LEN; i++) {
        arr[i][j] = i;
    }
}
finish = System.currentTimeMillis();
System.out.println("列优先访问消耗时间：" + (finish - start) + "ms");
```
> 输出：  
> 行优先访问消耗时间：60ms  
> 列优先访问消耗时间：1157ms

点击这里查看[完整代码][locality]。

以行序为主序对元素进行遍历，内层循环先访问第一行的元素，然后第二行......，而二维数组在存储器中也是按照行序为主序来进行存储的。
也就是说先存储第一行，然后第二行......，如下图所示。本例中存储顺序和访问顺序一致。所以可以该程序对a[][]的引用有良好的空间局部性。

以列序为主序，即先访问第一列，在访问第二列......，意味着每访问一个元素，就要跳过N个元素才能访问下一个。
这种情况下没有良好的空间局部性。

![二维数组][2d-arr]

# 3. CPU 缓存与局部性原理

`CPU`缓存（Cache Memory）是位于`CPU`与内存之间的临时存储器，它的容量比内存小的多但是交换速度却比内存要快得多。
缓存的出现主要是为了解决`CPU`运算速度与内存读写速度不匹配的矛盾，因为`CPU`运算速度要比内存读写速度快很多，
这样会使`CPU`花费很长时间等待数据到来或把数据写入内存。在缓存中的数据是内存中的一小部分，但这一小部分是短时间内`CPU`即将访问的，
当`CPU`调用大量数据时，就可避开内存直接从缓存中调用，从而加快读取速度。由此可见，在`CPU`中加入缓存是一种高效的解决方案，
这样整个内存储器（缓存+内存）就变成了既有缓存的高速度，又有内存的大容量的存储系统了。

缓存对`CPU`的性能影响很大，主要是因为`CPU`的数据交换顺序和`CPU`与缓存间的带宽引起的。缓存的工作原理是当`CPU`要读取一个数据时，
首先从缓存中查找，如果找到就立即读取并送给`CPU`处理；如果没有找到，就用相对慢的速度内存中读取并送给`CPU`处理，
同时把这个数据所在的数据块调入缓存中，可以使得以后对整块数据的读取都从缓存中进行，不必再调用内存。
正是这样的读取机制使`CPU`读取缓存的**命中率**非常高（大多数`CPU`可达 90% 左右），也就是说`CPU`下一次要读取的数据90%都在缓存中，
大约 10% 需要从内存读取。这大大节省了`CPU`直接读取内存的时间，也使`CPU`读取数据时基本无需等待。

总的来说，`CPU`读取数据的顺序是先缓存后内存。按照数据读取顺序和与`CPU`结合的紧密程度，`CPU`缓存可以分为一级缓存，二级缓存，
部分高端`CPU`还具有三级缓存，每一级缓存中所储存的全部数据都是下一级缓存的一部分，这三种缓存的技术难度和制造成本是相对递减的，
所以其容量也是相对递增的。当`CPU`要读取一个数据时，首先从一级缓存中查找，如果没有找到再从二级缓存中查找，
如果还是没有就从三级缓存或内存中查找。一般来说，每级缓存的命中率大概都在 80% 左右，也就是说全部数据量的 80% 都可以在一级缓存中找到，
只剩下 20% 的总数据量才需要从二级缓存、三级缓存或内存中读取，由此可见一级缓存是整个`CPU`缓存架构中最为重要的部分。

下图给出了计算机存储的整体架构：

![计算机存储架构][storage]

下面是各级存储的大致大小和访问速度：

![各级存储大小和访问速度][performance]

从最快的`L1 Cache`到最慢的`HDD`，其两者的访存时间差距达到了 6 个数量级，即便是和内存比较，也有几百倍的差距。举个例子，
如果`CPU`在运算是直接从内存中读取指令和数据，执行一条指令 0.3ns，然后从内存读下一条指令，等 120ns，
这样`CPU` 99% 计算时间都会被浪费掉。

如果我们的程序有良好的局部性，那么就`cpu`就更可能在缓存中找到程序的下一次指令，使得缓存命中率大大提升。因此，
我们应该尽量让写的程序满足局部性原理。基本方法就是：
1. 让最常见的情况运行的快，程序大部分的运行实际都花在少了核心函数上，而这些函数把大部分时间都花在少量循环上，
把注意力放在这些代码上。
2. 让每个循环内缓存不命中率最小。比如尽量不要列遍历二维数组、在循环中使用同一个局部变量。


[1d-arr]: ../../../res/img/locality-1d-arr.png
[2d-arr]: ../../../res/img/locality-2d-arr.jpg
[locality]: ../../../test/ujava/lang/LocalityTest.java
[storage]: ../../../res/img/locality-storage.png
[performance]: ../../../res/img/locality-performance.png